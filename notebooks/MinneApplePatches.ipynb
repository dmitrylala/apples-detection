{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.ops import box_iou, remove_small_boxes, nms, box_convert\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "\n",
    "from apples_detection.data.minneapple import MinneAppleDetectionModule\n",
    "from apples_detection.utils.visualize import visualize_apples\n",
    "from apples_detection.data.components.utils import add_leading_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e73f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/home/dmitry/Desktop/apples-detection/data/\")\n",
    "MINNEAPPLE_DIR = DATA_DIR / \"minneapple-detection\"\n",
    "CKPT_PATH = DATA_DIR / \"models/best_faster_rcnn_09.04.23.ckpt\"\n",
    "PATCHIFIER_PATH = DATA_DIR / \"minneapple-detection/test-patches_inst4_ker400max/patchifier.pkl\"\n",
    "PREDS_DIR = DATA_DIR / \"minneapple-detection/test-patches_inst4_ker400max/preds\"\n",
    "GT_PATH = DATA_DIR / \"minneapple-test/detection/ground_truth.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_patches = MinneAppleDetectionModule(\n",
    "    data_dir=MINNEAPPLE_DIR, \n",
    "    patches_suffix=\"-patches_inst4_ker400max\", \n",
    "    flip=False,\n",
    "    test_gt=\"../data/minneapple-test/detection/ground_truth.json\",\n",
    ")\n",
    "# ds_patches.setup(\"fit\")\n",
    "ds_patches.setup(\"predict\")\n",
    "ds_patches.setup(\"test\")\n",
    "\n",
    "ds_full = MinneAppleDetectionModule(data_dir=MINNEAPPLE_DIR, flip=False)\n",
    "# ds_full.setup(\"fit\")\n",
    "ds_full.setup(\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_patches(img_shape: Tuple[int, int], strides: Tuple[int, int], kernel_size: Tuple[int, int]):\n",
    "    return tuple([\n",
    "            (img_shape[i] - kernel_size[i] + strides[i]) / strides[i] for i in range(2)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ed731",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_n_patches([1200, 720], patchifier.strides, patchifier.kernel_size), patchifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f0bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1200 - 256 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATCHIFIER_PATH, \"rb\") as f:\n",
    "    patchifier = pickle.load(f)\n",
    "\n",
    "patches_shape = (6, 3)\n",
    "total_patches = math.prod(patches_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_size(\n",
    "    strides: Tuple[int, int],\n",
    "    kernel_size: Tuple[int, int],\n",
    "    patches_shape: Tuple[int, int],\n",
    ") -> Tuple[int, int]:\n",
    "    return tuple([patches_shape[j] * strides[j] + kernel_size[j] - strides[j] for j in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    if len(batch[0]) == 2:\n",
    "        return tuple(zip(*batch))\n",
    "    return batch\n",
    "\n",
    "preds_files = sorted(PREDS_DIR.glob(\"*predictions*.pt\"))\n",
    "predictions = list(itertools.chain.from_iterable((torch.load(path, map_location=\"cpu\") for path in preds_files)))\n",
    "# predictions_dl = DataLoader(\n",
    "#     predictions,\n",
    "#     batch_size=2,\n",
    "#     num_workers=1,\n",
    "#     collate_fn=collate_fn\n",
    "# )\n",
    "\n",
    "# patches_dl = DataLoader(\n",
    "#     ds_patches.data_val,\n",
    "#     batch_size=15,\n",
    "#     num_workers=3,\n",
    "#     collate_fn=collate_fn,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3074e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_boxes(\n",
    "    bbox1: torch.Tensor,\n",
    "    bbox2: torch.Tensor,\n",
    "    policy: str = \"union\",\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Expects bboxes in pascal_voc format: [x_min, y_min, x_max, y_max]\n",
    "    \"\"\"\n",
    "\n",
    "    if policy == \"union\":\n",
    "        return torch.Tensor([\n",
    "            min(bbox1[0], bbox2[0]), min(bbox1[1], bbox2[1]),\n",
    "            max(bbox1[2], bbox2[2]), max(bbox1[3], bbox2[3]),\n",
    "        ])\n",
    "    raise ValueError(f\"Policy {policy} not supported\")\n",
    "\n",
    "\n",
    "def postprocess(\n",
    "    boxes: torch.Tensor,\n",
    "    min_size: float,\n",
    "    scores: Optional[torch.Tensor] = None,\n",
    "    iou_thres: float = 0.5,\n",
    "):\n",
    "    boxes_idx = remove_small_boxes(boxes, min_size)\n",
    "\n",
    "    if scores is None:\n",
    "        return (boxes[boxes_idx], None)\n",
    "    \n",
    "    boxes, scores = boxes[boxes_idx], scores[boxes_idx]\n",
    "    nms_idx = nms(boxes.float(), scores, iou_thres)\n",
    "    return boxes[nms_idx], scores[nms_idx]\n",
    "\n",
    "    #     def criteria(box):\n",
    "#         h, w = box[3] - box[1], box[2] - box[0]\n",
    "#         squareness = min(h, w) / max(h, w)\n",
    "#         return squareness\n",
    "#     scores = torch.Tensor([criteria(box) for box in boxes])\n",
    "#     return masks[nms(boxes, scores, 0.2), :, :]\n",
    "\n",
    "\n",
    "def merge_patch_detections(\n",
    "    patchifier,\n",
    "    detections: List[Dict[str, torch.Tensor]],\n",
    "    patches_shape: Tuple[int, int],\n",
    "    min_size: float = 0.0,\n",
    "    nms_iou_thres: float = 0.5,\n",
    "    merge_iou_thres: float = 0.2,\n",
    "):\n",
    "    n_rows, n_cols = patches_shape\n",
    "    strides_h, strides_w = patchifier.strides\n",
    "    kernel_h, kernel_w = patchifier.kernel_size\n",
    "    offsets_h = [i * strides_h for i in range(n_rows)]\n",
    "    offsets_w = [j * strides_w for j in range(n_cols)]\n",
    "\n",
    "    merged_detections = None\n",
    "    for row, offset_h in enumerate(offsets_h):\n",
    "        row_detections = detections[n_cols * row : n_cols * (row + 1)]\n",
    "        row_merged_detections = None\n",
    "        for col, (patch_detections, offset_w) in enumerate(zip(row_detections, offsets_w)):\n",
    "            boxes = patch_detections[\"boxes\"]\n",
    "            if \"scores\" in patch_detections:\n",
    "                boxes = torch.hstack([boxes, patch_detections[\"scores\"].reshape(-1, 1)])\n",
    "            \n",
    "            if boxes.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            # bboxes in format [xmin, ymin, xmax, ymax, confidence]\n",
    "            # translate boxes x coords to global coords of image\n",
    "            boxes[:, [0, 2]] += offset_w\n",
    "            \n",
    "            if row_merged_detections is None:\n",
    "                row_merged_detections = boxes.clone()\n",
    "                continue\n",
    "            \n",
    "            pairwise_iou = box_iou(row_merged_detections[:, :4], boxes[:, :4])\n",
    "            \n",
    "            to_merge = torch.argwhere(pairwise_iou > merge_iou_thres)\n",
    "            for existing_idx, merge_idx in to_merge:\n",
    "                row_merged_detections[existing_idx, :4] = merge_boxes(\n",
    "                    row_merged_detections[existing_idx, :4],\n",
    "                    boxes[merge_idx, :4],\n",
    "                )\n",
    "            \n",
    "            to_append = torch.argwhere(pairwise_iou.max(dim=0).values <= merge_iou_thres).unique()\n",
    "            if to_append.any():\n",
    "                row_merged_detections = torch.vstack([row_merged_detections, boxes[to_append]])\n",
    "        \n",
    "        if row_merged_detections is None:\n",
    "            continue\n",
    "        \n",
    "        # translate boxes y coords to global coords of image\n",
    "        row_merged_detections[:, [1, 3]] += offset_h\n",
    "\n",
    "        if merged_detections is None:\n",
    "            merged_detections = row_merged_detections.clone()\n",
    "            continue\n",
    "\n",
    "        pairwise_row_iou = box_iou(merged_detections[:, :4], row_merged_detections[:, :4])\n",
    "\n",
    "        to_merge = torch.argwhere(pairwise_row_iou > merge_iou_thres)\n",
    "        for existing_idx, merge_idx in to_merge:\n",
    "            merged_detections[existing_idx, :4] = merge_boxes(\n",
    "                merged_detections[existing_idx, :4],\n",
    "                row_merged_detections[merge_idx, :4],\n",
    "            )\n",
    "\n",
    "        to_append = torch.argwhere(pairwise_row_iou.max(dim=0).values <= merge_iou_thres).unique()\n",
    "        if to_append.any():\n",
    "            merged_detections = torch.vstack([merged_detections, row_merged_detections[to_append]])\n",
    "    \n",
    "    if merged_detections is None:\n",
    "        return {\n",
    "            \"boxes\": torch.zeros(0, 4).int(),\n",
    "            \"scores\": torch.zeros(0).float(),\n",
    "            \"labels\": torch.ones(0).int()\n",
    "        }\n",
    "\n",
    "    boxes = merged_detections[:, :4].int()\n",
    "    scores = torch.ones(boxes.shape[0]).float() if merged_detections.shape[1] == 4 else merged_detections[:, 4].float()\n",
    "    boxes, scores = postprocess(boxes, min_size, scores=scores, iou_thres=nms_iou_thres)\n",
    "\n",
    "    merged_detections_dict = {\n",
    "        \"boxes\": boxes,\n",
    "        \"labels\": torch.ones(boxes.shape[0]).int(),\n",
    "        \"scores\": scores,\n",
    "    }\n",
    "\n",
    "    return merged_detections_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for patch, pred in tqdm(zip(ds_patches.data_predict, predictions)):\n",
    "#     cur_map = acc([pred], [gt])\n",
    "    visualize_apples([(patch, pred)])\n",
    "    i += 1\n",
    "    \n",
    "    if i >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_size = 10\n",
    "nms_iou_thres = 0.3\n",
    "merge_iou_thres = 0.4\n",
    "# merge_iou_thres = 0.2\n",
    "\n",
    "ds = ds_full.data_predict\n",
    "\n",
    "preds = {}\n",
    "predictions_batch = []\n",
    "j = 0\n",
    "for patches_preds in tqdm(predictions):\n",
    "    predictions_batch.append(patches_preds)\n",
    "\n",
    "    if len(predictions_batch) == total_patches:\n",
    "        merged_target = merge_patch_detections(\n",
    "            patchifier, \n",
    "            predictions_batch, \n",
    "            patches_shape, \n",
    "            min_size, \n",
    "            nms_iou_thres,\n",
    "            merge_iou_thres,\n",
    "        )\n",
    "\n",
    "        img_name = ds.paths[j].name\n",
    "        preds[img_name] = (merged_target, j)\n",
    "        j += 1\n",
    "\n",
    "        predictions_batch.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb821852",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GT_PATH) as f:\n",
    "    gt_mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9847c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_by_id = defaultdict(list)\n",
    "for annotation in gt_mapping[\"annotations\"]:\n",
    "    annotations_by_id[annotation[\"image_id\"]].append(annotation[\"bbox\"])\n",
    "\n",
    "for img_id in annotations_by_id:\n",
    "    annotations_by_id[img_id] = box_convert(torch.Tensor(annotations_by_id[img_id]).int(), in_fmt=\"xywh\", out_fmt=\"xyxy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = MeanAveragePrecision()\n",
    "\n",
    "for j, image_info in tqdm(enumerate(gt_mapping[\"images\"])):\n",
    "    image_name = str(add_leading_zeros(Path(image_info[\"filename\"])))\n",
    "    cur_preds, i = preds[image_name]\n",
    "    image = ds[i]\n",
    "\n",
    "    img_id = image_info[\"id\"]\n",
    "    gt_boxes = annotations_by_id[img_id]\n",
    "    gt = {\n",
    "        \"boxes\": gt_boxes,\n",
    "        \"scores\": torch.ones(gt_boxes.shape[0]).float(),\n",
    "        \"labels\": torch.ones(gt_boxes.shape[0]).int()\n",
    "    }\n",
    "    cur_map = acc([cur_preds], [gt])\n",
    "    print(cur_map)\n",
    "    break\n",
    "#     visualize_apples([(image, gt), (image, cur_preds)])\n",
    "\n",
    "print(acc.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05325b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {\n",
    "    'map': 0.3106, \n",
    "    'map_50': 0.5941, \n",
    "    'map_75': 0.2973, \n",
    "    'map_small': 0.1834, \n",
    "    'map_medium': 0.4036, \n",
    "    'map_large': 0.0198,\n",
    "}\n",
    "\n",
    "gt = {\n",
    "    \"map\": 0.482,\n",
    "    \"map_50\": 0.806,\n",
    "    \"map_75\": 0.513,\n",
    "    \"map_small\": 0.331,\n",
    "    \"map_medium\": 0.64,\n",
    "    \"map_large\": 0.937,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea13105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.show_metrics import gather_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57335b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map</th>\n",
       "      <th>map_50</th>\n",
       "      <th>map_75</th>\n",
       "      <th>map_small</th>\n",
       "      <th>map_medium</th>\n",
       "      <th>map_large</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <td>0.482000</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_faster_rcnn_09.04.23</th>\n",
       "      <td>0.361082</td>\n",
       "      <td>0.699418</td>\n",
       "      <td>0.341001</td>\n",
       "      <td>0.217737</td>\n",
       "      <td>0.478240</td>\n",
       "      <td>0.525579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patches_ker400_min4_epoch11</th>\n",
       "      <td>0.344575</td>\n",
       "      <td>0.679586</td>\n",
       "      <td>0.319454</td>\n",
       "      <td>0.243952</td>\n",
       "      <td>0.451921</td>\n",
       "      <td>0.561748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patches_ker400_min4_epoch28</th>\n",
       "      <td>0.314439</td>\n",
       "      <td>0.633367</td>\n",
       "      <td>0.282121</td>\n",
       "      <td>0.214450</td>\n",
       "      <td>0.434960</td>\n",
       "      <td>0.691258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merged_patches_04.04.23</th>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.594100</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.403600</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  map    map_50    map_75  map_small   \n",
       "model                                                                  \n",
       "gt                           0.482000  0.806000  0.513000   0.331000  \\\n",
       "best_faster_rcnn_09.04.23    0.361082  0.699418  0.341001   0.217737   \n",
       "patches_ker400_min4_epoch11  0.344575  0.679586  0.319454   0.243952   \n",
       "patches_ker400_min4_epoch28  0.314439  0.633367  0.282121   0.214450   \n",
       "merged_patches_04.04.23      0.310600  0.594100  0.297300   0.183400   \n",
       "\n",
       "                             map_medium  map_large  \n",
       "model                                               \n",
       "gt                             0.640000   0.937000  \n",
       "best_faster_rcnn_09.04.23      0.478240   0.525579  \n",
       "patches_ker400_min4_epoch11    0.451921   0.561748  \n",
       "patches_ker400_min4_epoch28    0.434960   0.691258  \n",
       "merged_patches_04.04.23        0.403600   0.019800  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gather_metrics(\"../data/metrics\").iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b462bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
