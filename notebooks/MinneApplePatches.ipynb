{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "from apples_detection.data.minneapple import MinneAppleDetectionModule\n",
    "from apples_detection.utils.visualize import visualize_apples\n",
    "from apples_detection.models.components.faster_rcnn import FasterRCNN\n",
    "from apples_detection.models.minneapple_detection import MinneAppleDetectionLitModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e73f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = \"/home/dmitry/Desktop/apples-detection/data/models/best_model_27.03.23.ckpt\"\n",
    "PATCHIFIER_PATH = \"/home/dmitry/Desktop/apples-detection/data/minneapple-detection/train-patches/patchifier.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_patches = MinneAppleDetectionModule(data_dir=\"../data/minneapple-detection/\", flip=False, use_patches=True)\n",
    "ds_patches.setup(\"fit\")\n",
    "\n",
    "ds_full = MinneAppleDetectionModule(data_dir=\"../data/minneapple-detection/\", flip=False, use_patches=False)\n",
    "ds_full.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FasterRCNN()\n",
    "opt = torch.optim.Adam(params=net.parameters())\n",
    "\n",
    "model = MinneAppleDetectionLitModule(net, opt).load_from_checkpoint(CKPT_PATH, map_location=\"cpu\", net=net)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATCHIFIER_PATH, \"rb\") as f:\n",
    "    patchifier = pickle.load(f)\n",
    "\n",
    "patches_shape = (5, 3)\n",
    "total_patches = math.prod(patches_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_size(\n",
    "    strides: Tuple[int, int],\n",
    "    kernel_size: Tuple[int, int],\n",
    "    patches_shape: Tuple[int, int],\n",
    ") -> Tuple[int, int]:\n",
    "    return tuple([patches_shape[j] * strides[j] + kernel_size[j] - strides[j] for j in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3074e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_patch_detections(\n",
    "    patchifier,\n",
    "    detections: List[Dict[str, torch.Tensor]],\n",
    "    patches_shape: Tuple[int, int],\n",
    "):\n",
    "    n_rows, n_cols = patches_shape\n",
    "    strides_h, strides_w = patchifier.strides\n",
    "    kernel_h, kernel_w = patchifier.kernel_size\n",
    "    offsets_h = [i * strides_h for i in range(n_rows)]\n",
    "    offsets_w = [j * strides_w for j in range(n_cols)]\n",
    "    \n",
    "    image_h, image_w = restore_size(patchifier.strides, patchifier.kernel_size, patches_shape)\n",
    "    \n",
    "    iou_thres = 0.2\n",
    "\n",
    "    merged_detections = None\n",
    "    for row, offset_h in enumerate(offsets_h):\n",
    "        row_detections = detections[n_cols * row : n_cols * (row + 1)]\n",
    "        row_merged_detections = None\n",
    "        for patch_detections, offset_w in zip(row_detections, offsets_w):\n",
    "            boxes = patch_detections[\"boxes\"]\n",
    "            if boxes.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            # bboxes in format [xmin, ymin, xmax, ymax]\n",
    "            boxes[:, [1, 3]] += offset_h\n",
    "            boxes[:, [0, 2]] += offset_w\n",
    "            print(boxes)\n",
    "            \n",
    "            \n",
    "        \n",
    "        break\n",
    "#             target = torch.zeros(row_patch.shape[0], kernel_h, image_w)\n",
    "#             target[:, :, offset_w : offset_w + kernel_w] = row_patch\n",
    "#             if masks is None:\n",
    "#                 masks = target.clone().type(torch.ByteTensor)\n",
    "#                 continue\n",
    "\n",
    "#             pairwise_iou = box_iou(\n",
    "#                 masks_to_boxes(masks), masks_to_boxes(target.type(torch.ByteTensor))\n",
    "#             )\n",
    "\n",
    "#             to_merge = torch.argwhere(pairwise_iou > iou_thres)\n",
    "#             not_to_merge = torch.argwhere(\n",
    "#                 pairwise_iou.max(dim=0).values <= iou_thres\n",
    "#             ).unique()\n",
    "\n",
    "#             for existing_idx, merge_idx in to_merge:\n",
    "#                 masks[existing_idx, :, :] = masks[existing_idx, :, :].logical_or(\n",
    "#                     target[merge_idx, :, :]\n",
    "#                 )\n",
    "\n",
    "#             if len(not_to_merge) > 0:\n",
    "#                 masks = torch.cat([masks, target[not_to_merge, :, :]], axis=0).type(\n",
    "#                     torch.ByteTensor\n",
    "#                 )\n",
    "\n",
    "#             del target\n",
    "        \n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_detections: List[Dict[str, torch.Tensor]] = []\n",
    "\n",
    "patches_data: List[Dict[str, torch.Tensor]] = []\n",
    "for i, (image, target) in enumerate(ds_patches.data_val):\n",
    "    [pred] = net(image.unsqueeze(0))\n",
    "    patches_data.append(pred)\n",
    "\n",
    "    if len(patches_data) == total_patches:\n",
    "        merged_target = merge_patch_detections(patchifier, patches_data, patches_shape)\n",
    "        patches_data.clear()\n",
    "        merged_detections.append(merged_target)\n",
    "        visualize_apples([(image, target), (image, pred)], confidence_threshold=0.0, nrow=3)\n",
    "        break\n",
    "\n",
    "# merged_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = [image for image, _ in ds_patches.data_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f848e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ee940",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    print(ds_patches.data_val.get_img_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    image, target = ds_patches.data_val[i]\n",
    "    [pred] = model(image.unsqueeze(0))\n",
    "    data = [(image, {}), (image, target), (image, pred)]\n",
    "    visualize_apples(data, nrow=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc11b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
